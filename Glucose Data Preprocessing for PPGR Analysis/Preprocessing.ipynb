{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Glucose Data Preprocessing for PPGR Analysis\n",
        "\n",
        "## Introduction\n",
        "This notebook preprocesses continuous glucose monitoring (CGM), meal, and insulin data to isolate and analyze postprandial glucose response (PPGR) events. The workflow includes data import, event alignment, filtering, and calculation of net glucose responses after accounting for insulin action. Each step is annotated with concise explanations to clarify the logic and methodology."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1S83NDQhV0x2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.table import Table\n",
        "import seaborn as sns\n",
        "import os\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import datetime\n",
        "from datetime import timedelta\n",
        "from statistics import mode\n",
        "from scipy.signal import find_peaks\n",
        "\n",
        "\n",
        "from scipy.integrate import odeint\n",
        "\n",
        "# Libraries for Correlations\n",
        "import scipy.stats as stats\n",
        "from scipy.stats import pearsonr, sem, variation, kruskal,f_oneway\n",
        "from scipy.cluster.hierarchy import linkage, fcluster, dendrogram\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from itertools import combinations, permutations\n",
        "\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports and Setup\n",
        "\n",
        "The notebook begins by importing essential libraries for data manipulation (`pandas`, `numpy`), visualization (`matplotlib`, `seaborn`), and scientific computation (`scipy`, `sklearn`). These libraries enable efficient data processing, statistical analysis, and plotting. The `%matplotlib inline` magic ensures plots are rendered within the notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-WQVdMjV0x5"
      },
      "source": [
        "############################################\n",
        "\n",
        "Processing the Glucose Values to Isolate the PPGR\n",
        "\n",
        "############################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Methodology Overview\n",
        "\n",
        "The main objective is to identify and extract postprandial glucose response (PPGR) events from the raw dataset. This involves:\n",
        "- Reading and timestamp-aligning glucose, meal, and insulin data.\n",
        "- Merging and interleaving meal and bolus (insulin) events to create a unified event timeline.\n",
        "- Associating each event with the closest glucose measurement and relevant metadata.\n",
        "- Filtering and structuring the data for further analysis of glucose excursions after meals and insulin dosing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8OiR9kSTV0x6"
      },
      "outputs": [],
      "source": [
        "def read_data(filename):\n",
        "    unfiltered = pd.read_csv(os.path.join(filename))\n",
        "    # Use the detected 'MacRoman' encoding\n",
        "    #unfiltered = pd.read_csv(os.path.join(filename), encoding='MacRoman')\n",
        "    unfiltered['bg_ts'] = pd.to_datetime(unfiltered['bg_ts'], dayfirst=True, errors='coerce')\n",
        "    unfiltered['meal_ts'] = pd.to_datetime(unfiltered['meal_ts'], dayfirst=True, errors='coerce')\n",
        "    unfiltered['bolus_ts'] = pd.to_datetime(unfiltered['bolus_ts'], dayfirst=True, errors='coerce')\n",
        "\n",
        "    return unfiltered\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Function: read_data\n",
        "\n",
        "This function loads the participant's data from a CSV file, parses relevant timestamp columns (glucose, meal, bolus), and returns a cleaned DataFrame. This ensures all subsequent processing uses consistent datetime formats."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ge7_45RpV0x7"
      },
      "outputs": [],
      "source": [
        "def interleave_arrays_increasing(meal, bolus):\n",
        "    \"\"\"Interleave two sorted arrays in increasing order.\n",
        "\n",
        "    NOTE: Here, the term 'interleave' refers to the specific process of merging two sequences by alternating their elements.\n",
        "    \"\"\"\n",
        "    result = []\n",
        "    i, j = 0, 0\n",
        "    while i < len(meal) and j < len(bolus):\n",
        "        if meal[i] < bolus[j]:\n",
        "            result.append((\"meal\", meal[i]))\n",
        "            i += 1\n",
        "        else:\n",
        "            result.append((\"bolus\", bolus[j]))\n",
        "            j += 1\n",
        "    result.extend([(\"meal\", meal[x]) for x in range(i, len(meal))])\n",
        "    result.extend([(\"bolus\", bolus[x]) for x in range(j, len(bolus))])\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Function: interleave_arrays_increasing\n",
        "\n",
        "This function merges two sorted arrays (meal and bolus event timestamps) into a single timeline, tagging each entry by its source. This is crucial for analyzing the sequence and timing of meal and insulin events relative to glucose measurements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**def interleave_arrays_increasing(...)**\n",
        "*Notes from Copilot*\n",
        "\n",
        "The function `interleave_arrays_increasing` takes two input lists, `meal` and `bolus`, and merges them into a single list called `result`. The merging process is done in increasing order, assuming both input lists are already sorted in ascending order. The function uses two pointers, `i` and `j`, to track the current position in the `meal` and `bolus` lists, respectively.\n",
        "\n",
        "Inside the `while` loop, the function compares the current elements of `meal` and `bolus`. If the current `meal` value is less than the current `bolus` value, it appends a tuple `(\"meal\", meal[i])` to the result and advances the `meal` pointer. Otherwise, it appends a tuple `(\"bolus\", bolus[j])` and advances the `bolus` pointer. This process continues until one of the lists is fully traversed.\n",
        "\n",
        "After the loop, there may be remaining elements in either `meal` or `bolus`. The function then extends the `result` list with the remaining elements from each list, tagging them appropriately as either `\"meal\"` or `\"bolus\"`. The final output is a single list of tuples, each indicating the source (\"meal\" or \"bolus\") and the value, all in increasing order. This approach is similar to the merge step in the merge sort algorithm and is efficient for combining two sorted lists."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Function: glucoseForMealsTs\n",
        "\n",
        "Finds the closest glucose measurement for each meal timestamp. This step is essential for associating meal events with the most relevant glucose readings, enabling accurate analysis of postprandial responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dnG5TxpkV0x7"
      },
      "outputs": [],
      "source": [
        "def glucoseForMealsTs(glucose_ts_array, meal_ts):\n",
        "    closest_values = []\n",
        "    for element in meal_ts:\n",
        "        closest_index = np.abs(glucose_ts_array - element).argmin()\n",
        "        closest_values.append(glucose_ts_array[closest_index])\n",
        "    return np.array(closest_values)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Function: glucoseForEventsTs\n",
        "\n",
        "For each event (meal or bolus), this function finds the closest glucose timestamp within a 4-hour window. This ensures that only temporally relevant glucose readings are linked to each event, improving the quality of downstream analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XEvYo6EIV0x7"
      },
      "outputs": [],
      "source": [
        "def glucoseForEventsTs(glucose_ts_array, events_ts):\n",
        "    closest_values = []\n",
        "    for event_type, event_ts in events_ts:\n",
        "        closest_index = np.abs(glucose_ts_array - event_ts).argmin()\n",
        "        closest_value = glucose_ts_array[closest_index]\n",
        "\n",
        "        if abs(closest_value - event_ts) <= pd.Timedelta(hours=4):\n",
        "            closest_values.append((event_type, event_ts, closest_value))\n",
        "\n",
        "    return closest_values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BZ9c8jx5V0x7"
      },
      "outputs": [],
      "source": [
        "def bolusMealSeparation(meal_ts, bolus_start_ts, bolus_dose_filtered):\n",
        "    viableBolusTimes = []\n",
        "    for i in range(min(len(bolus_start_ts), len(bolus_dose_filtered))):\n",
        "        isWithinRange = False\n",
        "        for j in range(len(meal_ts)):\n",
        "            if meal_ts[j] - pd.Timedelta(minutes=4) <= bolus_start_ts[i] <= meal_ts[j] + pd.Timedelta(hours=4):\n",
        "                isWithinRange = True\n",
        "                break\n",
        "        if not isWithinRange:\n",
        "            viableBolusTimes.append((bolus_start_ts[i], bolus_dose_filtered[i]))\n",
        "    return viableBolusTimes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Function: bolusMealSeparation\n",
        "\n",
        "Filters bolus (insulin) events to exclude those that are temporally close to meal events. This helps isolate bolus events that are independent of meals, which is important for distinguishing meal-driven from insulin-driven glucose changes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EbWOAZJWV0x8"
      },
      "outputs": [],
      "source": [
        "def groupBolus2(bolus_array):\n",
        "    time_ranges = [\n",
        "        (\"6am-10am\", datetime.time(6, 0), datetime.time(10, 0)),\n",
        "        (\"10am-2pm\", datetime.time(10, 0), datetime.time(14, 0)),\n",
        "        (\"2pm-6pm\", datetime.time(14, 0), datetime.time(18, 0)),\n",
        "        (\"6pm-10pm\", datetime.time(18, 0), datetime.time(22, 0)),\n",
        "    ]\n",
        "\n",
        "    result = []\n",
        "    df = pd.DataFrame(bolus_array, columns=['Timestamp', 'Value'])\n",
        "    grouped = df.groupby(df['Timestamp'].dt.date)\n",
        "\n",
        "    for date, group_data in grouped:\n",
        "        daily_result = {'Date': date, 'TimeRanges': []}\n",
        "        for label, start_time, end_time in time_ranges:\n",
        "            time_mask = (group_data['Timestamp'].dt.time >= start_time) & (group_data['Timestamp'].dt.time < end_time)\n",
        "            max_value = group_data.loc[time_mask, 'Value'].max()\n",
        "            max_timestamps = group_data.loc[(time_mask) & (group_data['Value'] == max_value), 'Timestamp'].tolist()\n",
        "            daily_result['TimeRanges'].append({\n",
        "                'TimeRange': label,\n",
        "                'MaxValue': max_value,\n",
        "                'Timestamps': max_timestamps\n",
        "            })\n",
        "        result.append(daily_result)\n",
        "    return result\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Function: groupBolus2\n",
        "\n",
        "Groups bolus events by day and predefined time ranges (e.g., morning, afternoon, evening). For each range, it identifies the maximum bolus dose and its timestamps. This categorization supports time-of-day analysis of insulin administration patterns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3Q9-X0j_V0x8"
      },
      "outputs": [],
      "source": [
        "def findTimestampsNotCoveredByMeals(result, meal_events):\n",
        "    time_ranges = {\n",
        "        \"6am-10am\": (datetime.time(6, 0), datetime.time(10, 0)),\n",
        "        \"10am-2pm\": (datetime.time(10, 0), datetime.time(14, 0)),\n",
        "        \"2pm-6pm\": (datetime.time(14, 0), datetime.time(18, 0)),\n",
        "        \"6pm-10pm\": (datetime.time(18, 0), datetime.time(22, 0))\n",
        "    }\n",
        "\n",
        "    meal_events_set = set(meal_events)\n",
        "    timestamps_not_covered = []\n",
        "\n",
        "    for day_result in result:\n",
        "        for time_range_result in day_result['TimeRanges']:\n",
        "            time_range_label = time_range_result['TimeRange']\n",
        "            timestamps = time_range_result['Timestamps']\n",
        "            time_range_start, time_range_end = time_ranges[time_range_label]\n",
        "\n",
        "            meal_events_within_range = False\n",
        "            for meal in meal_events_set:\n",
        "                meal_time = meal.time()\n",
        "                time_range_start_datetime = datetime.datetime.combine(day_result['Date'], time_range_start)\n",
        "                time_range_end_datetime = datetime.datetime.combine(day_result['Date'], time_range_end)\n",
        "\n",
        "                if time_range_start_datetime <= meal <= time_range_end_datetime:\n",
        "                    meal_events_within_range = True\n",
        "                    break\n",
        "\n",
        "            if not meal_events_within_range:\n",
        "                timestamps_not_covered.extend(timestamps)\n",
        "    return timestamps_not_covered\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Function: findTimestampsNotCoveredByMeals\n",
        "\n",
        "Identifies bolus event timestamps that do not overlap with any meal events within the same time range. This step further refines the set of insulin events to those most likely independent of food intake."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TwxYLIgCV0x8"
      },
      "outputs": [],
      "source": [
        "def filter_glucose_levels(glucose_ts_array, glucose_level_array, event_ts):\n",
        "    start_time = event_ts\n",
        "    end_time = event_ts + pd.Timedelta(hours=4)\n",
        "    filtered_glucose_levels = []\n",
        "    previous_timestamp = None\n",
        "    for ts, level in zip(glucose_ts_array, glucose_level_array):\n",
        "        if start_time <= ts <= end_time:\n",
        "            if previous_timestamp is not None and (ts - previous_timestamp) > pd.Timedelta(minutes=30):\n",
        "                break\n",
        "            filtered_glucose_levels.append(level)\n",
        "            previous_timestamp = ts\n",
        "    return filtered_glucose_levels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Function: filter_glucose_levels\n",
        "\n",
        "Extracts glucose values within a 4-hour window after an event, ensuring no large gaps between measurements. This provides a clean glucose trajectory for each event, suitable for PPGR analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4y0nSgOBV0x8"
      },
      "source": [
        "###################################\n",
        "\n",
        "Read and format DataFrame\n",
        "\n",
        "###################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Import and Initial Formatting\n",
        "\n",
        "This section loads the participant's data, sorts it by glucose timestamp, and extracts relevant columns (glucose, meal, bolus, carbs, tags). This prepares the data for event alignment and further processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OEODu0MxV0x8"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'meal_ts'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\RobbieDocuments\\ManchesterCSCoordinatedDiabetesStudy\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[31mKeyError\u001b[39m: 'meal_ts'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      4\u001b[39m participant_file = gpath / \u001b[33m'\u001b[39m\u001b[33mUoMGlucose2301.csv\u001b[39m\u001b[33m'\u001b[39m  \u001b[38;5;66;03m# Update this with the actual file name\u001b[39;00m\n\u001b[32m      6\u001b[39m insulin_sensitivity_factor = \u001b[32m5.8\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m unfiltered = \u001b[43mread_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparticipant_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m unfiltered.sort_values(\u001b[33m'\u001b[39m\u001b[33mbg_ts\u001b[39m\u001b[33m'\u001b[39m, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     10\u001b[39m unfiltered.reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mread_data\u001b[39m\u001b[34m(filename)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Use the detected 'MacRoman' encoding\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m#unfiltered = pd.read_csv(os.path.join(filename), encoding='MacRoman')\u001b[39;00m\n\u001b[32m      5\u001b[39m unfiltered[\u001b[33m'\u001b[39m\u001b[33mbg_ts\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(unfiltered[\u001b[33m'\u001b[39m\u001b[33mbg_ts\u001b[39m\u001b[33m'\u001b[39m], dayfirst=\u001b[38;5;28;01mTrue\u001b[39;00m, errors=\u001b[33m'\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m unfiltered[\u001b[33m'\u001b[39m\u001b[33mmeal_ts\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(\u001b[43munfiltered\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmeal_ts\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m, dayfirst=\u001b[38;5;28;01mTrue\u001b[39;00m, errors=\u001b[33m'\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      7\u001b[39m unfiltered[\u001b[33m'\u001b[39m\u001b[33mbolus_ts\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(unfiltered[\u001b[33m'\u001b[39m\u001b[33mbolus_ts\u001b[39m\u001b[33m'\u001b[39m], dayfirst=\u001b[38;5;28;01mTrue\u001b[39;00m, errors=\u001b[33m'\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m unfiltered\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\RobbieDocuments\\ManchesterCSCoordinatedDiabetesStudy\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\RobbieDocuments\\ManchesterCSCoordinatedDiabetesStudy\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
            "\u001b[31mKeyError\u001b[39m: 'meal_ts'"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "# Read data from the original file\n",
        "gpath = Path(\"D:/RobbieDocuments/ManchesterCSCoordinatedDiabetesStudy/Glucose Data\")\n",
        "participant_file = gpath / 'UoMGlucose2301.csv'  # Update this with the actual file name\n",
        "\n",
        "insulin_sensitivity_factor = 5.8\n",
        "\n",
        "unfiltered = read_data(participant_file)\n",
        "unfiltered.sort_values('bg_ts', inplace=True)\n",
        "unfiltered.reset_index(drop=True, inplace=True)\n",
        "\n",
        "bg_ts = pd.to_datetime(unfiltered['bg_ts'].copy().to_numpy(), dayfirst=True, errors='coerce')\n",
        "glucose_level = unfiltered['glucose_level'].copy().to_numpy()  # Already converted to mmol/L\n",
        "bolus_ts = pd.to_datetime(unfiltered['bolus_ts'].copy().to_numpy(), dayfirst=True, errors='coerce')\n",
        "meal_ts = pd.to_datetime(unfiltered['meal_ts'].copy().to_numpy(), dayfirst=True, errors='coerce')\n",
        "\n",
        "bolus_dose = unfiltered['bolus_dose'].copy().to_numpy()\n",
        "carbs_g = unfiltered['carbs_g']\n",
        "meal_tags = unfiltered['meal_tag']\n",
        "meal_types = unfiltered['meal_Type']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Event Filtering and Alignment\n",
        "\n",
        "Filters out invalid or missing values from meal and bolus arrays, then aligns meal and bolus events with glucose data. This step produces arrays of event-glucose pairs, ready for feature extraction and further analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYUc4v16V0x9"
      },
      "outputs": [],
      "source": [
        "\n",
        "nan_mask = np.isnan(bolus_dose)\n",
        "bolus_dose_filtered = bolus_dose[~nan_mask]\n",
        "\n",
        "nat_mask = np.isnat(meal_ts)\n",
        "meal_ts_filtered = meal_ts[~nat_mask]\n",
        "\n",
        "nat_mask = np.isnat(bolus_ts)\n",
        "bolus_start_ts_filtered = bolus_ts[~nat_mask]\n",
        "\n",
        "closest_glucose_array_meals = glucoseForMealsTs(glucose_level_ts, meal_ts_filtered)\n",
        "\n",
        "bolusAndValueArray = bolusMealSeparation(meal_ts_filtered, bolus_start_ts_filtered, bolus_dose_filtered)\n",
        "max_bolus_time_range = groupBolus2(bolusAndValueArray)\n",
        "bolus_replacement_array = findTimestampsNotCoveredByMeals(max_bolus_time_range, meal_ts_filtered)\n",
        "\n",
        "interleaved_meal_bolus_array = interleave_arrays_increasing(meal_ts_filtered, bolus_replacement_array)\n",
        "closest_glucose_meal_bolus_array = glucoseForEventsTs(glucose_level_ts, interleaved_meal_bolus_array)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tug0NCNJV0x9"
      },
      "outputs": [],
      "source": [
        "# Extract 'carbs_g' and 'meal_tags' from the original data\n",
        "carbs_g = unfiltered['carbs_g']\n",
        "\n",
        "data_points = []\n",
        "\n",
        "for event_type, event_ts, glucose_ts in closest_glucose_meal_bolus_array:\n",
        "    closest_index = np.abs(glucose_level_ts - glucose_ts).argmin()\n",
        "    glucose_levels = glucose_level[closest_index:closest_index + 48]\n",
        "\n",
        "    carbs_value = unfiltered.loc[unfiltered['meal_ts'] == event_ts, 'carbs_g'].values[0] if event_type == \"meal\" else None\n",
        "    meal_tag_value = unfiltered.loc[unfiltered['meal_ts'] == event_ts, 'meal_tag'].values[0] if event_type == \"meal\" else None\n",
        "    meal_type_value = unfiltered.loc[unfiltered['meal_ts'] == event_ts, 'meal_Type'].values[0] if event_type == \"meal\" else None\n",
        "    bolus_dose_value = unfiltered.loc[unfiltered['meal_ts'] == event_ts, 'bolus_dose'].values[0] if event_type == \"meal\" else None\n",
        "    bolus_time = unfiltered.loc[unfiltered['meal_ts'] == event_ts, 'bolus_ts'].values[0] if event_type == \"meal\" else None\n",
        "\n",
        "    data_point = {\n",
        "        \"EventTimestamp\": event_ts,\n",
        "        \"GlucoseLevels\": glucose_levels,\n",
        "        \"EventType\": event_type,\n",
        "        \"EventTag\": carbs_value,\n",
        "        \"MealTag\": meal_tag_value,\n",
        "        \"MealType\": meal_type_value,\n",
        "        \"BolusTime\" : bolus_time,\n",
        "        \"BolusDose\" : bolus_dose_value\n",
        "    }\n",
        "    data_points.append(data_point)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Building the Event-Feature Dataset\n",
        "\n",
        "For each event (meal or bolus), this section extracts a window of glucose values and relevant metadata (carbs, meal type, bolus dose, etc.). The result is a structured list of event-feature dictionaries, which is then converted into a DataFrame for analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpSBu76PV0x9"
      },
      "outputs": [],
      "source": [
        "# Assume data_points is already defined as your input DataFrame\n",
        "GlucoseEvents_exploded_clean = pd.DataFrame(data_points)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Engineering and Categorization\n",
        "\n",
        "Adds new columns to the event-feature DataFrame, such as day of the week, hour, and meal category. This enables stratified analysis of PPGR by time and meal type, even when explicit meal labels are missing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9B_4sVQV0x9",
        "outputId": "4063314f-4bc0-49ef-fd18-7533fb91872e"
      },
      "outputs": [],
      "source": [
        "\n",
        "GlucoseEvents_exploded_clean['EventTimestamp'] = pd.to_datetime(GlucoseEvents_exploded_clean['EventTimestamp'])\n",
        "GlucoseEvents_exploded_clean['day_of_the_week'] = GlucoseEvents_exploded_clean['EventTimestamp'].dt.dayofweek\n",
        "GlucoseEvents_exploded_clean['hour'] = GlucoseEvents_exploded_clean['EventTimestamp'].dt.hour\n",
        "\n",
        "# Ensure Meal_Type is prioritized for MealCategory\n",
        "GlucoseEvents_exploded_clean['MealCategory'] = GlucoseEvents_exploded_clean['MealType']\n",
        "\n",
        "# Assign time-based categories where MealType is not available\n",
        "time_based_categories = pd.cut(\n",
        "    GlucoseEvents_exploded_clean['hour'],\n",
        "    bins=[0, 10, 16, 22],\n",
        "    labels=['Breakfast', 'Lunch', 'Dinner'],\n",
        "    right=False\n",
        ")\n",
        "\n",
        "GlucoseEvents_exploded_clean['MealCategory'].fillna(time_based_categories, inplace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inspecting the Event-Feature DataFrame\n",
        "\n",
        "Displays the processed DataFrame to verify that all features and event alignments are correct before further analysis. This step is useful for debugging and validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QlLuduSV0x9",
        "outputId": "a5c18627-767d-4384-e53d-481b96a5c53b"
      },
      "outputs": [],
      "source": [
        "# Print the DataFrame\n",
        "print(GlucoseEvents_exploded_clean)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modeling Insulin Action and Calculating Net Response\n",
        "\n",
        "Defines a function to model the effect of rapid-acting insulin on glucose levels, then applies it to each event. The resulting 'NetResponse' column represents glucose trajectories adjusted for insulin action, isolating the meal-driven component of PPGR."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkBD_46rV0x-",
        "outputId": "cd36e938-e230-4a3a-c846-54c3f3198d10"
      },
      "outputs": [],
      "source": [
        "# Function to compute insulin action profile for rapid-acting insulin\n",
        "def insulin_action_profile(time, bolus_time, insulin_dose, insulin_sensitivity):\n",
        "    insulin_effect = np.zeros_like(time, dtype=float)\n",
        "\n",
        "    for i, t in enumerate(time):\n",
        "        if t >= bolus_time + 15 and t < bolus_time + 240:\n",
        "            if t <= bolus_time + 60:\n",
        "                insulin_effect[i] = -1 * (t - bolus_time - 15) * (insulin_dose * insulin_sensitivity / 45)  # onset to peak\n",
        "            else:\n",
        "                insulin_effect[i] = -1 * (insulin_dose * insulin_sensitivity - ((t - bolus_time - 60) * (insulin_dose * insulin_sensitivity / 180)))  # peak to end\n",
        "\n",
        "    return insulin_effect\n",
        "\n",
        "\n",
        "# Initialize an empty list to store net responses\n",
        "net_responses = []\n",
        "\n",
        "# Iterate over each row in the GlucoseEvents DataFrame\n",
        "for index, row in GlucoseEvents_exploded_clean.iterrows():\n",
        "    # Get the necessary parameters for insulin action\n",
        "    bolus_time = row['BolusTime']  # This should be a pandas Timestamp\n",
        "    bolus_dose = row['BolusDose']\n",
        "    glucose_levels = row['GlucoseLevels']\n",
        "\n",
        "    # Remove non-numeric glucose levels (e.g., 'Low', 'High', etc.)\n",
        "    cleaned_glucose_levels = []\n",
        "    for glucose in glucose_levels:\n",
        "        try:\n",
        "            cleaned_glucose_levels.append(float(glucose))  # Try converting to float\n",
        "        except ValueError:  # If it fails, skip or handle accordingly\n",
        "            cleaned_glucose_levels.append(np.nan)  # Replace non-numeric with NaN (or handle as needed)\n",
        "\n",
        "    # Convert the list of glucose levels to a numpy array for calculations\n",
        "    glucose_levels = np.array(cleaned_glucose_levels)\n",
        "\n",
        "    # Convert BolusTime to minutes since the start of the observation\n",
        "    start_time = row['EventTimestamp']  # Reference time (event time)\n",
        "    bolus_time_in_minutes = (bolus_time - start_time).total_seconds() / 60.0  # Convert to minutes\n",
        "\n",
        "    # Create a time vector based on the length of glucose_levels\n",
        "    time = np.arange(len(glucose_levels)) * 5  # Assuming glucose levels are recorded every 5 minutes\n",
        "\n",
        "    # Calculate the insulin effect based on the bolus dose and time\n",
        "    insulin_effect = insulin_action_profile(time, bolus_time_in_minutes, bolus_dose, insulin_sensitivity_factor)\n",
        "\n",
        "    # Calculate net response by adjusting glucose levels for insulin effect\n",
        "    net_response = glucose_levels + insulin_effect  # Element-wise addition\n",
        "\n",
        "    # Store the net response\n",
        "    net_responses.append(net_response)\n",
        "\n",
        "# Add the net responses to the GlucoseEvents DataFrame\n",
        "GlucoseEvents_exploded_clean['NetResponse'] = net_responses\n",
        "\n",
        "# Display the updated DataFrame\n",
        "print(GlucoseEvents_exploded_clean[['EventTimestamp', 'GlucoseLevels', 'BolusTime', 'BolusDose', 'NetResponse']])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Final Output and Next Steps\n",
        "\n",
        "The processed DataFrame now contains event-aligned glucose trajectories, event metadata, and net responses adjusted for insulin action. This dataset is ready for statistical analysis, visualization, or machine learning to study PPGR patterns and their determinants."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "1th0iYlwV0x_",
        "outputId": "c5ffe1c4-fbc9-459c-ac98-fcfcce6e422c"
      },
      "outputs": [],
      "source": [
        "GlucoseEvents_exploded_clean.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exporting Processed Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the processed DataFrame to a new CSV file\n",
        "processed_df.to_csv(\"processed_glucose_data.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
